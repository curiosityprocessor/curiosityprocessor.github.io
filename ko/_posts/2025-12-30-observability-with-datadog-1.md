---
title: "Datadog을 통한 Observability 확보 여정 #1"
date: 2025-12-30
lang: ko
categories:
  - DevOps
tags:
  - DevOps
  - Solutions
excerpt: "#1 Monitoring에서 Observability로"
---

# Monitoring 개선부터
## 로그의 소유자 찾기
### 백엔드
가장 먼저 한 작업은 **커스텀 컨텍스트**를 심는 과정이었다.  
다만 백엔드만 하더라도 같은 프레임워크 베이스라도 코드베이스가 조금씩 달랐고,  
로그를 남기는 방식도 통일되지 않아 개발자간 개인 편차도 심했다.  

그래서 **공통적으로, 일괄적으로** 커스텀 컨텍스트를 주입하는 방식이 필요했다.  
커스텀 로거를 구현하거나 로그 패턴을 제시하는 방법도 있겠지만 그에 우선하여  
모든 API 요청에 대해 사전작업을 처리할 수 있는 **인터셉터** 단에서 커스텀 컨텍스트를 주입하는 방식부터 택했다.  
다행히도 필수로 여긴 기업번호와 고객번호는 대부분의 API 요청에서 직접 받고 있거나, 간접적으로 조회 가능했다.  
인터셉터에서는 현재 활성화된 데이터독의 trace와 span을 가져와 거기에 기업번호와 고객번호를 주입해  
이 요청에서 발생하는 모든 로그에서 커스텀 컨텍스트를 함께 남길 수 있도록 만들었다.  

### 서버리스
서버리스는 백엔드보다 훨씬 더 파편화된 환경이었다.  
**아무거나 실행**할 수 있는 환경이다보니, **아무렇게나 만든** 코드도 올릴 수 있었고  
프레임워크도 없다보니 로그의 커버리지나 형식도 제각각이었다.  

여기서는 컨텍스트와 더불어 일관된 로그를 남기기 위한 **커스텀 로거** 작업도 추가했다.  
코드베이스를 일원화하기 위한 템플릿 작업과 함께 람다 함수내 개별 함수의 시작, 종료, 소요 시간  
그리고 파라미터와 리턴값을 자동으로 남기기 위한 로거를 공통 패키지화하여 제공하고  
자동으로 흔히 쓰는 컨텍스트를 모든 로그에 주입시키도록 했다.  
그리고 로그 형식 또한 json으로 통일하여 데이터독에서 필드를 추출해 검색, 필터링 가능하게 바꾸었다.  

이를 통해 서버리스 로그 역시 **누가, 언제, 무엇을, 얼마나 걸려 요청**했는지 파악할 수 있게 되었다.  

## 로그의 범위 파악하기
한 명의 사용자는 한 페이지만 접속해도 여러번에 걸쳐 API를 보낼 수 있고, 여러 페이지를 거쳐갈 수 있으니  
백엔드 단에서 하나의 요청 흐름만 추적하는 것으론 부족했다.  
다만 기업번호와 고객번호로 추적할 수 있게 되면서 대략적으로 같은 사용자가 요청한 거겠거니 추측은 할 수 있게 됐다.  
(체감상 디버깅, 장애 대응의 70% 정도는 이 선에서 가능해졌던 것 같다)  

하지만 API 로그로 추적되지 않는 액션 (브라우저 액션, 캐싱된 응답 등) 과 동시접속과 같은 케이스까지 보려면  
결국 프론트엔드 모니터링까지 필요했고 데이터독의 RUM(Real User Monitoring) 을 연동하게 되었다.  
RUM은 사용자의 세션별로 어떤 페이지에서 어떤 액션을 했는지 추적할 수 있을 뿐만 아니라  
기존에 연동된 백엔드 서버와 트레이스 연계를 지원하여  
이제 프론트부터 백엔드를 넘나들며 사용자 세션 단위로 추적이 가능해졌다.  

## 로그는 정리됐고, 다음은?
지금까지의 작업은 이미 발생한 에러에 대해 어떻게 추적할 수 있는지 **사후 분석** 관점의 작업이었다.  
여전히 장애를 **인지**하는 작업은 수작업으로 또는 고객의 문의로 이루어졌기에  
다음 우선 순위로는 **사전 감지** 단계의 작업이 필요했다. 

먼저 시스템 차원에서 종종 예기치 않은 OOM 이슈로 서버가 죽고는 했는데 이에 대응하기 위해  
Java로 구동하는 백엔드 서버의 좀 더 시스템 내부적인 수치인 jvm metrics를 연동했고,  
백엔드는 물론 서버리스 환경에서도 CPU, 메모리 사용량 같은 **metrics**를 집계했다.  

그 외에 주요 API의 응답속도를 점검하기 위한 **테스트 자동화**도 추가했다.
관리자 사이트와 사용자 사이트의 핵심 API에 대해 주기적으로 요청하고  
평균 응답속도가 기준치를 초과하면 팀즈 알림을 받을 수 있도록 웹훅으로 연동했다.  

또한 주요 에러 발생 시에도 마찬가지로 **알림**을 연동해 즉각적으로 대응할 수 있도록 했다.  

## 한눈에 필요한 정보만 보기위한 대시보드
주요 알림을 받고 데이터독에 들어와서도 이슈 추적을 위해서는 여러 페이지들을 넘나들며 확인해야했고,  
데이터독에서 제공하는 기능별 페이지는 많은 정보를 제공했지만 우리가 **우선적으로 필요한 정보를 한 눈에 보기**는 어려웠다.  
결국 한 눈에 필요한 정보만 볼 수 있는 커스텀 대시보드가 필요해졌다.  

대시보드를 만들다보니 이런 것도 있으면 좋겠다 싶은게 하나둘 생기기 시작했다.  
- 응답시간, 전주/전일 대비 요청량 변화, 기업별 호출 비중, 관리자/사용자 호출 비중과 같은 **트래픽/사용량** 관점
- 프론트, API, DB별 주요 에러 유형 및 건수, http status 비중과 같은 **에러/디버깅** 관점  
- CPU, 메모리, ECS task 수와 같은 **시스템** 관점

여러가지 정보가 추가되기 시작했고 어플리케이션의 전체적인 상태를 볼 수 있는 화면으로 자리잡기 시작했다.  
디버깅을 하거나, 장애 대응을 한다면 여기부터 보면 된다는 **스타팅 포인트**가 된 것이다.  

# Monitoring을 넘어 Observability로
Monitoring이란 사전에 정의한 지표나 이슈에 대한 지속적인 관찰로  
풀어 얘기하자면 **이미 알고 있는 이슈**에 대한 점검이다.  
Observability는 시스템 내부에서 어떤 일이 일어나고 있는지 **설명할 수 있는 능력**이고  
이를 통해 알고 있는 이슈의 현상파악은 물론 **숨겨진 이슈**도 발굴해 낼 수 있다.  

대시보드를 만들면서 에러 케이스에 대한 추적이 편해진 점은 물론  
에러는 아니지만 **비정상적**인 혹은 **잠재적으로 이슈**가 될 만한 상황을 탐지할 수 있게 되었다.  

예를 들어 요청량이 늘었을 때,  
API별 편차 없이 전체적으로 늘어난다면 일반적인 사용량 증가를 의미하니 스케일 아웃을 고려하면 됐고  
특정한 API의 응답시간이 높아졌다면 해당 기능을 점검하면 됐다.  
특정 기업의 요청 비중이 높아진다면 그 기업의 이벤트를 찾아보면 됐고  
특정 사용자의 요청 비중이 높아진다면 악의적인 사용자인지 또는 해당 사용자의 전/후 세션에서 잠재적인 이슈가 있었는지 파악하면 됐다.  

대시보드를 통해 자연스럽게 **monitoring에서 observability로** 넘어가게 된 것이다.
